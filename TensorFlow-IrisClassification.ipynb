{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>Iris Classification with TensorFlow</h1> </center>\n",
    "\n",
    "In this Jupyter notebook we want to learn the basics of the higher level machine learning TensorFlow API (tf.contrib.learn). There are many built-in features which makes it easy to configure, train and evaluate a model.\n",
    "\n",
    "As an example we focus on the famous [*Iris Flower Dataset*](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "\n",
    "  Iris Setosa (0)   | Iris Versicolor (1)   | Iris Virginicar (2)\n",
    "  -------------  | -------------   |--------------\n",
    "  ![alt](IrisClassifier/Kosaciec_szczecinkowaty_Iris_setosa.jpg \"Logo Title Text 1\")   | ![alt](IrisClassifier/220px-Iris_versicolor_3.jpg \"Logo Title Text 1\") | ![alt](IrisClassifier/220px-Iris_virginica.jpg \"Logo Title Text 1\")\n",
    "  \n",
    "We want to build a neural network which acts as a classifier and after it is trained assigns the feature vector which consists of the sepal and tepal width and length to one of the three different Iris species.\n",
    "\n",
    "First, let us import the relevant packages and the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(data=array([[ 5.9000001 ,  3.        ,  4.19999981,  1.5       ],\n",
      "       [ 6.9000001 ,  3.0999999 ,  5.4000001 ,  2.0999999 ],\n",
      "       [ 5.0999999 ,  3.29999995,  1.70000005,  0.5       ],\n",
      "       [ 6.        ,  3.4000001 ,  4.5       ,  1.60000002],\n",
      "       [ 5.5       ,  2.5       ,  4.        ,  1.29999995],\n",
      "       [ 6.19999981,  2.9000001 ,  4.30000019,  1.29999995],\n",
      "       [ 5.5       ,  4.19999981,  1.39999998,  0.2       ],\n",
      "       [ 6.30000019,  2.79999995,  5.0999999 ,  1.5       ],\n",
      "       [ 5.5999999 ,  3.        ,  4.0999999 ,  1.29999995],\n",
      "       [ 6.69999981,  2.5       ,  5.80000019,  1.79999995],\n",
      "       [ 7.0999999 ,  3.        ,  5.9000001 ,  2.0999999 ],\n",
      "       [ 4.30000019,  3.        ,  1.10000002,  0.1       ],\n",
      "       [ 5.5999999 ,  2.79999995,  4.9000001 ,  2.        ],\n",
      "       [ 5.5       ,  2.29999995,  4.        ,  1.29999995],\n",
      "       [ 6.        ,  2.20000005,  4.        ,  1.        ],\n",
      "       [ 5.0999999 ,  3.5       ,  1.39999998,  0.2       ],\n",
      "       [ 5.69999981,  2.5999999 ,  3.5       ,  1.        ],\n",
      "       [ 4.80000019,  3.4000001 ,  1.89999998,  0.2       ],\n",
      "       [ 5.0999999 ,  3.4000001 ,  1.5       ,  0.2       ],\n",
      "       [ 5.69999981,  2.5       ,  5.        ,  2.        ],\n",
      "       [ 5.4000001 ,  3.4000001 ,  1.70000005,  0.2       ],\n",
      "       [ 5.5999999 ,  3.        ,  4.5       ,  1.5       ],\n",
      "       [ 6.30000019,  2.9000001 ,  5.5999999 ,  1.79999995],\n",
      "       [ 6.30000019,  2.5       ,  4.9000001 ,  1.5       ],\n",
      "       [ 5.80000019,  2.70000005,  3.9000001 ,  1.20000005],\n",
      "       [ 6.0999999 ,  3.        ,  4.5999999 ,  1.39999998],\n",
      "       [ 5.19999981,  4.0999999 ,  1.5       ,  0.1       ],\n",
      "       [ 6.69999981,  3.0999999 ,  4.69999981,  1.5       ],\n",
      "       [ 6.69999981,  3.29999995,  5.69999981,  2.5       ],\n",
      "       [ 6.4000001 ,  2.9000001 ,  4.30000019,  1.29999995]], dtype=float32), target=array([1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 2, 0, 2, 1, 1, 0, 1, 0, 0, 2, 0, 1, 2,\n",
      "       1, 1, 1, 0, 1, 2, 1]))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "IRIS_TRAINING = \"/home/jodahr/Jupyter/IrisClassifier/iris_training.csv\"\n",
    "IRIS_TEST = \"/home/jodahr/Jupyter/IrisClassifier/iris_test.csv\"\n",
    "\n",
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TRAINING,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TEST,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "\n",
    "# print test set to show the structure\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see it is very easy to load the data in the desired form (Labeled Point) including a feature vector (data) and the label (target). If more feature engineering is needed you can have a look [here](https://www.tensorflow.org/get_started/input_fn).\n",
    "\n",
    "Next, we can already configure the model. First we need to define the feature columns. For more information you can have a look at [https://www.tensorflow.org/api_docs/python/tf/contrib/layers/real_valued_column](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/real_valued_column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3ce853d5f8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/iris_model'}\n"
     ]
    }
   ],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "# default: activation_fn=tf.nn.relu\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            activation_fn=tf.nn.sigmoid,\n",
    "                                            model_dir=\"/tmp/iris_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'Const:0' shape=(120, 4) dtype=float32>, <tf.Tensor 'Const_1:0' shape=(120,) dtype=int64>)\n"
     ]
    }
   ],
   "source": [
    "# Define the training inputs\n",
    "def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return x, y\n",
    "\n",
    "# tuple containg feature vector and label\n",
    "print(get_train_inputs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jodahr/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0467828, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 647.449\n",
      "INFO:tensorflow:loss = 0.0462221, step = 4101 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.38\n",
      "INFO:tensorflow:loss = 0.0456386, step = 4201 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.875\n",
      "INFO:tensorflow:loss = 0.045146, step = 4301 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.569\n",
      "INFO:tensorflow:loss = 0.0446019, step = 4401 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.561\n",
      "INFO:tensorflow:loss = 0.0440831, step = 4501 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.834\n",
      "INFO:tensorflow:loss = 0.0437302, step = 4601 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.303\n",
      "INFO:tensorflow:loss = 0.0431262, step = 4701 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.016\n",
      "INFO:tensorflow:loss = 0.042684, step = 4801 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.401\n",
      "INFO:tensorflow:loss = 0.0422665, step = 4901 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.273\n",
      "INFO:tensorflow:loss = 0.0417817, step = 5001 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.093\n",
      "INFO:tensorflow:loss = 0.041459, step = 5101 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.124\n",
      "INFO:tensorflow:loss = 0.0409473, step = 5201 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.84\n",
      "INFO:tensorflow:loss = 0.0405817, step = 5301 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.96\n",
      "INFO:tensorflow:loss = 0.0401763, step = 5401 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.713\n",
      "INFO:tensorflow:loss = 0.0397724, step = 5501 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.747\n",
      "INFO:tensorflow:loss = 0.0394535, step = 5601 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.212\n",
      "INFO:tensorflow:loss = 0.0390242, step = 5701 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.491\n",
      "INFO:tensorflow:loss = 0.0387232, step = 5801 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.977\n",
      "INFO:tensorflow:loss = 0.0383249, step = 5901 (0.167 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0380012.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x7f3ce853d278>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function sigmoid at 0x7f3d03585510>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model.\n",
    "classifier.fit(input_fn=get_train_inputs, steps=2000)\n",
    "\n",
    "# Same as\n",
    "#classifier.fit(x=training_set.data, y=training_set.target, steps=1000)\n",
    "#classifier.fit(x=training_set.data, y=training_set.target, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jodahr/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-02-20:53:09\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-6000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-02-20:53:09\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.966667, global_step = 6000, loss = 0.0772428\n",
      "\n",
      "Test Accuracy: 0.966667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the test inputs\n",
    "def get_test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=get_test_inputs,\n",
    "                                     steps=1)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jodahr/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:347: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-6000\n",
      "New Samples, Class Predictions:    [1, 2, 0, 1, 1, 1, 0, 1, 1, 2, 2, 0, 2, 1, 1, 0, 1, 0, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1, 2, 1]\n",
      "\n",
      "[1 2 0 1 1 1 0 2 1 2 2 0 2 1 1 0 1 0 0 2 0 1 2 1 1 1 0 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Classify two new flower samples.\n",
    "def new_samples():\n",
    "    return np.array(\n",
    "    [[6.4, 3.2, 4.5, 1.5],\n",
    "    [6.4,2.8,5.6,2.2]], dtype=np.float32)\n",
    "\n",
    "def test():\n",
    "    return test_set.data\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=test))\n",
    "print(\n",
    "    \"New Samples, Class Predictions:    {}\\n\"\n",
    "    .format(predictions))\n",
    "\n",
    "print(test_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = \"/tmp/iris_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TB(cleanup=False):\n",
    "    import webbrowser\n",
    "    webbrowser.open('http://127.0.1.1:6006')\n",
    "\n",
    "    !tensorboard --logdir=\"/tmp/iris_model\"\n",
    "\n",
    "    if cleanup:\n",
    "        !rm -R logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'54' at http://jodahr-Lenovo-IdeaPad-Y510P:6006\n",
      "(Press CTRL+C to quit)\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n"
     ]
    }
   ],
   "source": [
    "TB(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
